seed: 42  # random seed
output_dir: ./output/hpt_train # output directory
domains: Robotwin  # domains to train on
wb_tag: "hpt_exp"  # wandb tag
log_interval: 10  # how many steps before logging to wandb
script_name: "hpt_train"  # log the running script
pretrained_dir: "./hpt-xlarge"  # pretrained model directory (can be local path)
parallel_eval: False  # use ray to do parallel evaluation

# dataset parameters
task_name: stack_blocks_two  # task name
task_config: demo_clean  # task config
episode_num: 100  # number of episodes to collect
processed_data_dir: ./processed_data  # processed data save path
total_num_traj: 100
# dataset config
dataset:
  _target_: hpt.dataset.local_traj_dataset.LocalTrajDataset  # 数据集类
  horizon: 1  # 每个样本的 horizon（未使用）
  val_ratio: 0.1  # 训练/验证集比例
  pad_after: 0  # episode 后填充
  episode_cnt: ${episode_num}  # 总 episode 数
  step_cnt: 32000 # 总数据步数
  data_augmentation: False  # 是否数据增强
  use_disk: True  # 是否用磁盘存储数据
  pad_before: 0  # episode 前填充
  data_ratio: 1  # 只用部分数据
  action_horizon: 8  # 动作 horizon
  observation_horizon: 4  # 观测 horizon
  dataset_postfix: "_traj${dataset.episode_cnt}"  # 数据集后缀
  image_encoder: 'resnet'  # 图像编码器
  dataset_encoder_postfix: "_${dataset.image_encoder}"  # 编码器后缀
  dataset_name: Robotwin # 数据集名称
  precompute_feat: True  # 是否预计算特征
  use_multiview: True  # 是否多视角
  normalize_state: True  # 是否归一化状态
  regenerate: False  # 是否重新生成数据
  action_multiple_horizon: True  # 动作维度乘以 horizon
  random_mask_obs: True  # 随机观测长度
  data_augment_ratio: 1  # 图像数据增强比例
  proprioception_expand: False  # 是否扩展本体感知
  proprioception_expand_dim: 32  # 本体感知扩展维度
  env_rollout_fn:  # 数据集转换函数
    _target_: policy.HPT.process_data.convert_dataset_robotwin_cached  # 数据集转换函数类
    task_name: ${task_name}  # 任务名
    task_config: ${task_config}  # 任务配置
    episode_num: ${episode_num}  # episode 数
    use_cache: True  # 是否使用缓存
    save_dir: ${processed_data_dir}  # 保存路径

# 主干 transformer 配置
network:
  _target_: hpt.models.policy.Policy  # policy class
  embed_dim: 768 # trunk transformer embedding dimension
  num_blocks: 16  # number of blocks in the trunk transformer
  num_heads: 8  # number of heads in the trunk transformer
  drop_path: 0.1  # drop path in the trunk transformer
  use_modality_embedding: True # add trainable modality position tokens
  use_domain_embedding: False # whether to add domain-specific trainable parameters
  observation_horizon: ${dataset.horizon} # the observation history
  action_horizon: 8 # open loop action steps. <= the dataset action horizons
  token_postprocessing: "mean" # maxpool or meanpool the tokens
  cross_stem_attention: True # use cross attention to combine state and action
  weight_init_style: 'pytorch' # weight init
  no_trunk: False # ignore trunk
  finetune_encoder: False # whether to finetune encoders

# stem network for different modalities
stem:
  modalities: ['image', 'state'] # 'language'
  modality_embed_dim: ${network.embed_dim} # modality embedding dimension
  normalize_state: ${dataset.normalize_state} # normalize state vectors
  state_embedding_dim: 14 # dimension of positional encoding for state
  cross_attention: True # whether to use cross attention or not
  precompute_feat: True # whether to use precomputed features. if not, will finetune.
  image_encoder: ${dataset.image_encoder} # what image encoder to use
  crossattn_dim_head: 64 # for cross attention modules
  crossattn_heads: 8 # number of heads in cross attention
  crossattn_modality_dropout: 0.1 # the dropout ratio for cross attention
  num_blocks: 1 # number of blocks for stem transformer's cross and self attention
  observation_horizon: ${dataset.observation_horizon} # observation horizon
  masked_autoencoding: False # random mask encoding and then reconstruction
  random_horizon_masking: True # whether to randomize observation input length
  add_pos_embedding_to_state: False # positional embedding for the state
  crossattn_latent: # standardize token sizes for each modality
    image: 16 # image token size
    state: 16 # state token size
    language: 8
  image:
    _target_: hpt.models.policy_stem.MLP # image stem class
    input_dim: 512 # input dimension
    output_dim: ${network.embed_dim} # output dimension
    widths:  [128] # MLP layer widths
    num_of_copy: 1 # number of copies
  state:
    _target_: hpt.models.policy_stem.MLP # state stem class
    input_dim: ${stem.state_embedding_dim} # input dimension (overwrite based on the dataset)
    output_dim: ${network.embed_dim} # output dimension
    widths: [128] # MLP layer widths

# head 网络配置
head:
  _target_: hpt.models.policy_head.MLP  # head 类
  input_dim: ${network.embed_dim}  # head 输入维度
  tanh_end: False  # 是否归一化动作输出
  output_dim: 112  # 动作输出维度（需根据实际动作维度设置）
  widths: [256, 128]  # MLP 层宽度
  normalize_action: ${head.tanh_end}  # 是否归一化动作
  dropout: True  # 是否使用 dropout

# 训练参数
dataloader:
  batch_size: 128  # 训练 batch 大小
  num_workers: 4  # dataloader worker 数
  pin_memory: True  # 是否 pin memory
  persistent_workers: True  # 是否持久化 worker
  shuffle: True  # 是否打乱数据
  drop_last: False  # 是否丢弃最后一个 batch

val_dataloader:
  batch_size: 128  # validation batch size
  num_workers: 4  # validation dataloader worker number
  shuffle: False  # do not shuffle validation set
  pin_memory: True  # whether to use pin memory
  persistent_workers: True  # whether to persist workers
  drop_last: False  # whether to drop last batch

# optimizer config
optimizer:
  _target_: torch.optim.Adam  # optimizer type
  lr: 1e-4  # learning rate

# learning rate scheduler config
lr_scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR  # scheduler type
  T_max: ${train.total_epochs}  # maximum epoch
  eta_min: 1e-6  # minimum learning rate

# 训练流程参数
train:
  total_epochs: 1000  # maximum training epochs before termination. usually set as maximum
  total_iters: 2000000 # maximum training steps before termination
  epoch_iters: 1000  # training steps in each epoch
  validation_iters: 350 # maximum iterations for validation
  pretrained_dir: "./hpt-xlarge" # pretrained model path for testing
  freeze_trunk: True # whether to freeze the trunk during finetuning
  wandb_pretrained_dir: "" # use models pretrained on wandb

# optimizer misc config
optimizer_misc:
  nontrunk_lr_scale: 1. # non-trunk layer learning rate scale

# warmup learning rate config
warmup_lr:
  lr: 1e-10 # warmup initial learning rate
  step: 1000 # first 1000 iterations

gpu_id: 4